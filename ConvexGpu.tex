%!TEX encoding=UTF-8 Unicode

\documentclass[10pt, conference, compsocconf]{IEEEtran}

%=========================encodage fontes et langue=============================

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}    % (pour les accents)

%===============================================================================

%========================= gestion des hyperliens ==============================

\usepackage{cite}
\usepackage{url}
\usepackage{hyperref}
\hypersetup{
    breaklinks=true, %permet le retour à la ligne dans les liens trop longs
    urlcolor= blue, %couleur des hyperliens
    linkcolor= black, %couleur des liens internes
bookmarksopen=true} 

%===============================================================================

%=========================Mathématiques========================================

\usepackage[cmex10]{amsmath} 
\usepackage{array} % tableaux pour les matrices

%===============================================================================

%==========================inclusion d'images===================================

\usepackage[pdftex]{graphicx} % \includegraphics
\graphicspath{{./img/}}
%\usepackage[caption=false]{caption}
\usepackage[caption=false,font=footnotesize]{subfig}

%===============================================================================

%==========================listes et mise en page===============================

%\usepackage{paralist} % listes : enumerate, itemize
%\frenchbsetup{StandardLists=true} %pour avoir des listes avec des points

\usepackage[usenames,dvipsnames]{color} %de la couleur

%\usepackage{appendix} %Annexes

%===============================================================================

%=========================déclaration de titre=================================

\author{\IEEEauthorblockN{David Beniamine, Guillaume Huard}
    \IEEEauthorblockA{
        Université Joseph Fourier\\
        Laboratoire d'Informatique de Grenoble - Inria\\
        38330 Montbonnot St Martin, France\\
    david.beniamine@imag.fr, guillaume.huard@imag.fr}
}

\title{Reducing the impact of communication times on heterogeneous
applications scheduling using KAAPI }

%===============================================================================

\begin{document}

%==========================page de présentation================================

\maketitle%affichage du titre
\begin{abstract}
    High Performance Computing machines use more and more Graphical Processing
    Units as they are very efficient for homogeneous computation such as
    matrix operations. However before using these accelerators, one has to
    transfer data from the processor to them which can be slow. 

    In this study, our aim is to reduce the impact of communication times on
    the makespan of a scheduling. Indeed, with a better anticipation of these
    communications, we could use the GPUs even more efficiently. More
    precisely, we will focus on machines with many GPUs and on applications
    with a low ratio of computations over communications. 

    During this study, we have implemented two offline scheduling algorithms
    within  XKAAPI's runtime.  We have experimentally shown that, by combining
    communication aware scheduling algorithms, we can reduce substantially the
    makespan of a fine grain application.

    Finally our experiments have shown the impact of contention on the PCI bus
    on the makespan of mixed CPU/GPU applications. Moreover we have shown that
    even communications aware scheduling algorithms can be biased when their
    performance model doesn't consider the contention.

\end{abstract}

\begin{IEEEkeywords}
    GPU; Clustering; Scheduling; XKAAPI; Communications;

\end{IEEEkeywords}



%===============================================================================

%=========================début réel du document==============================
\section{Introduction}

To obtain portable performances, some runtimes such as XKAAPI
\cite{gautierxkaapi} or StarPU \cite{augonnet2011starpu} allow the programmer
to describe an application such as a set of tasks and dependencies.  They use
a workstealing algorithm \cite{blumofe1995cilk} to schedule theses tasks on
the available resources. As it provide a good load balancing, this algorithm
is quite efficient on homogeneous machines. However nowadays, HPC computers
includes many GPUs, which implies a lot of costly communications. Hence the
basic workstealing algorithm which doesn't manage theses communications can
provide bad performances.

\subsection{List scheduling algorithms}

%%% TODO : explain more the algorithms
The workstealing algorithm is an adaptation of the list scheduling which
provide a makespan $\omega\leq2\omega^*$ where $\omega^*$ is the optimal
makespan \cite{GrahamRL1966Bounds, GrahamRL1969Bounds}. However this bound is
true for homogeneous processors and with no communications. In a model with
heterogenous machines and no communications, this bounds grows to
$\omega\leq\min(s+2-\frac{2s+1}{n},\frac{n+1}{2})\omega^*$ where $s$ is the
number of different resources and $n$ the number of processors. Hence it
doesn't scale for current HPC computers. 

Earliest Task First\cite{hwang1989scheduling} is an adaptation for a finite
number of identical processors with a unitary communication cost between each
couples of processors and without contention.  This algorithm provide a bound
of $\omega\leq(2+c)\omega^*$ where $c$ is the maximum cost of one
communication.  
%%Description of the Idea here

Heterogeneous Earliest Finish Time \cite{topcuoglu2002performance} is also
based on the list algorithm nevertheless, it allow a processor to be idle when
a task is ready to be executed. 
%%%%%%More precise spec of HEFT here
Hence it doesn't provide any bound on the
execution time moreover recent work have shown that the worst case can provide
a makespan $\omega \geq \frac{m}{2}\omega^*$ where $m$ is the number of tasks
\cite{Kedad-SidhoumMonnaMounieEtAl2013}. Despite this results, the HEFT
algorithm is widely used (by StarPU and XKAAPI amongst others), and give some
good results in many case\cite{ferreiralima:hal-00735470}. Nevertheless, the
same study have shown that in some case this algorithm give better results
when we use only the half of the available GPUs.

If most of these algorithms are designed offline, they are often implemented
online on the runtimes scheduler. These online adaptations have a lower cost
than the original, however the neglect the outgoing work of a task when they
compute its schedule. Therefore the offline version should be more efficient
when the communications are costly.

\subsection{Clustering Algorithms}

Clustering algorithms are designed for an unbounded number of processors, they
consider the structure of the DAG and group tasks into clusters. All the
tasks which belong to one cluster are assigned to the same processor (i.e. 
there are no communication between them).  

One of the most known clustering heuristic is the Dominant Sequence
Clustering\cite{yang1994dsc}, it assigns to each task a priority corresponding
to the sum of the longest path from a root node to this task and the longest
path from this task to a sink node.Then the algorithm sort the tasks by
decreasing priority and try to affect each task to the cluster which minimize
its start time among the cluster containing its predecessors. However if a
task can start earlier when we assign it to a new cluster instead of assigning
it to an existing one, we create a new cluster for this task.

The idea of CLANS
\cite{aubum1990efficient,mccreary1993partitioning,mccreary1993graph} is to
decompose the DAG into a tree of clans representing a recursive expression of
the relationship between tasks. For a graph $G=(V,E)$, a set of nodes
$X\subset V$ is a clan of the graph $G$ if and only if $\forall (x,y) \in X,
\forall z \in V-X$, $z$ is an ancestor (or successor) of $x$ if and only if
$z$ an ancestor (resp. successor) of $y$. There are three types of clans:
Independent, linear and primitive. Once the graph is decomposed into clans,
the algorithm traverse the tree bottom up using the communication and
execution times to determine if two clans have to be merged or not.

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.3\textwidth]{conv.png}
    \caption{Convex and non convex group of tasks.}
    \label{fig:conv}
\end{figure}


The convex clustering algorithm\cite{lepere2002new} produces an acyclic graph
of clusters.  Indeed a cluster $C$ is convex if and only if $\forall\ (x,z)\
\in\ C$ all task $y$, such that $x\ \prec\ y\ \prec\ z$, is in $C$ (see
figure \ref{fig:conv}). By this property, we know that there are no two way
communications between two clusters. Moreover as the graph obtained by merging
the tasks inside a cluster is a Direct Acyclic Graph, it allow us to run
any scheduling algorithm on it.

A theoretical comparison\cite{khan1994comparison} between the algorithms DSC,
MCP (Modified Critical Path, similar to DSC), MH, HU (lists algorithms) and
CLANS have shown that CLANS is robust and efficient for a large and diverse
set of graphs. All the others algorithms give very bad performances for graphs
with a low ratio computation over communications (also called grain).

To study the impact of communication times, we want to reduce the grain of
the DAG by managing clusters as if they were large tasks. As  the dataflow
model implemented by XKAAPI doesn't allow cyclic dependencies between tasks,
the only algorithm which fits our needs is the convex clustering. Hence we
will implement this algorithm inside XKAAPI, and we are going to combine it
with the HEFT algorithm to understand the impact of communication times on a
scheduling. 

%%%%%
\textbf{TODO}
\\

\subsection{Key Issue}
All these algorithms are efficient when the grain is high, therefore in this study we
focus on very fine grain applications. 

=> Cncl Convex + offline HEFT Study impact of comm / contention

%%%TODO
\section{Implementation of an offline scheduler in XKAAPI's runtime}
+ Kaapi scheduling
\\
+ Perfmodel 
\\
+ Adaptation (algo)
\\
+ Importanc of the cost
\section{Analysis and reduction of the communication times}
+ Machines
\\
+ Off / on
\\
+ Convex
\\
+ Calibration
\section{Conclusions and future work}
+ Complex heuristic helps, but need a good perfmodel, and cost a lot
\\
=> reuse a scheduling 
\\
=> Combine offline init sched + online if too far from predictions
\\
=> More work on perfmodel
\\
+ Different Apps
%===============================================================================

%=========================Bibliographie========================================
%\IEEEtriggeratref{3}

\bibliographystyle{IEEEtran}
\bibliography{ConvexGpu}

%===============================================================================

%=========================annexes==============================================

%newpage
%\appendix{ \textbf{Annexe }}

%===============================================================================

\end{document}

